{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab048781",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc66ef",
   "metadata": {},
   "source": [
    "- Goal: classifies tweets with 5 groups (Extremely possitive/negative, possitive, negative & neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248ffe4",
   "metadata": {},
   "source": [
    "## Set Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b39d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182b396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling as pp\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469f6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aae0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('corona_tweet').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9eb801",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b251817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv('covid_text_classification\\Corona_NLP_train.csv', header = True, multiLine=True, inferSchema=True, escape='\"', dateFormat='dd-MM-yyyy')\n",
    "test = spark.read.csv('covid_text_classification\\Corona_NLP_test.csv', header = True, multiLine=True, inferSchema=True, escape='\"', dateFormat='dd-MM-yyyy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a258b",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "- The tweet have been pulled from Twitters and manual tagging has been done.\n",
    "- It's conatin 6 features:\n",
    "    - Username: UserId\n",
    "    - ScreenName: User's Screen id\n",
    "    - Location: Location when Tweet.\n",
    "    - TweetAt: Time making a Tweet.\n",
    "    - OriginalTweet: Tweet content.\n",
    "    - Sentiment: Type of Tweet (have 5 group listed above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3f78a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+--------------------+---------+\n",
      "|UserName|ScreenName| Location|   TweetAt|       OriginalTweet|Sentiment|\n",
      "+--------+----------+---------+----------+--------------------+---------+\n",
      "|    3799|     48751|   London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
      "|    3800|     48752|       UK|16-03-2020|advice Talk to yo...| Positive|\n",
      "|    3801|     48753|Vagabonds|16-03-2020|Coronavirus Austr...| Positive|\n",
      "+--------+----------+---------+----------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee240566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserName: integer (nullable = true)\n",
      " |-- ScreenName: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- TweetAt: string (nullable = true)\n",
      " |-- OriginalTweet: string (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb00beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+----------+--------------------+------------------+\n",
      "|UserName|ScreenName|   Location|   TweetAt|       OriginalTweet|         Sentiment|\n",
      "+--------+----------+-----------+----------+--------------------+------------------+\n",
      "|       1|     44953|        NYC|02-03-2020|TRENDING: New Yor...|Extremely Negative|\n",
      "|       2|     44954|Seattle, WA|02-03-2020|When I couldn't f...|          Positive|\n",
      "|       3|     44955|       null|02-03-2020|Find out how you ...|Extremely Positive|\n",
      "+--------+----------+-----------+----------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9c4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserName: integer (nullable = true)\n",
      " |-- ScreenName: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- TweetAt: string (nullable = true)\n",
      " |-- OriginalTweet: string (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38b85a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row & column of the dataset: 41157 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "print('Total row & column of the dataset:', train.count(), 'rows and', len(train.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4c3357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(UserName=3799, ScreenName=48751, Location='London', TweetAt='16-03-2020', OriginalTweet='@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8', Sentiment='Neutral')\n",
      "\n",
      "\n",
      "Row(UserName=3800, ScreenName=48752, Location='UK', TweetAt='16-03-2020', OriginalTweet='advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order', Sentiment='Positive')\n",
      "\n",
      "\n",
      "Row(UserName=3801, ScreenName=48753, Location='Vagabonds', TweetAt='16-03-2020', OriginalTweet='Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P', Sentiment='Positive')\n",
      "\n",
      "\n",
      "Row(UserName=3802, ScreenName=48754, Location=None, TweetAt='16-03-2020', OriginalTweet=\"My food stock is not the only one which is empty...\\r\\n\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\nStay calm, stay safe.\\r\\n\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\", Sentiment='Positive')\n",
      "\n",
      "\n",
      "Row(UserName=3803, ScreenName=48755, Location=None, TweetAt='16-03-2020', OriginalTweet=\"Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\n\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\n\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\", Sentiment='Extremely Negative')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in train.take(5):\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42cf4853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row & column of the dataset: 3798 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "print('Total row & column of the dataset:', test.count(), 'rows and', len(test.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66970b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(UserName=1, ScreenName=44953, Location='NYC', TweetAt='02-03-2020', OriginalTweet='TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1', Sentiment='Extremely Negative')\n",
      "\n",
      "\n",
      "Row(UserName=2, ScreenName=44954, Location='Seattle, WA', TweetAt='02-03-2020', OriginalTweet=\"When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\", Sentiment='Positive')\n",
      "\n",
      "\n",
      "Row(UserName=3, ScreenName=44955, Location=None, TweetAt='02-03-2020', OriginalTweet='Find out how you can protect yourself and loved ones from #coronavirus. ?', Sentiment='Extremely Positive')\n",
      "\n",
      "\n",
      "Row(UserName=4, ScreenName=44956, Location='Chicagoland', TweetAt='02-03-2020', OriginalTweet='#Panic buying hits #NewYork City as anxious shoppers stock up on food&amp;medical supplies after #healthcare worker in her 30s becomes #BigApple 1st confirmed #coronavirus patient OR a #Bloomberg staged event?\\r\\n\\r\\nhttps://t.co/IASiReGPC4\\r\\n\\r\\n#QAnon #QAnon2018 #QAnon2020 \\r\\n#Election2020 #CDC https://t.co/29isZOewxu', Sentiment='Negative')\n",
      "\n",
      "\n",
      "Row(UserName=5, ScreenName=44957, Location='Melbourne, Victoria', TweetAt='03-03-2020', OriginalTweet='#toiletpaper #dunnypaper #coronavirus #coronavirusaustralia #CoronaVirusUpdate #Covid_19 #9News  #Corvid19 #7NewsMelb #dunnypapergate #Costco    One week everyone buying baby milk powder the next everyone buying up toilet paper. https://t.co/ScZryVvsIh', Sentiment='Neutral')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in test.take(5):\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a062ba",
   "metadata": {},
   "source": [
    "The original tweet is a combination of many component: words, special character(@, /, etc) and web link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e30930",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82630f9a",
   "metadata": {},
   "source": [
    "#### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99bbfcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "UserName       0\n",
       "ScreenName     0\n",
       "Location       0\n",
       "TweetAt        0\n",
       "OriginalTweet  0\n",
       "Sentiment      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nan checking\n",
    "train.select([count(when(isnan(c), c)).alias(c) for c in train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057bd29",
   "metadata": {},
   "source": [
    "there is no nan value in this train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e02fcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "UserName          0\n",
       "ScreenName        0\n",
       "Location       8590\n",
       "TweetAt           0\n",
       "OriginalTweet     0\n",
       "Sentiment         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null checking\n",
    "train.select([count(when(col(c).isNull(), c)).alias(c) for c in train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab4155",
   "metadata": {},
   "source": [
    "No Null value in train data set because the read.csv with params listed above already delete the null row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e5a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of duplicate row: 0\n"
     ]
    }
   ],
   "source": [
    "#Duplicate value\n",
    "print('Total of duplicate row:', train.count() - train.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d9ac2",
   "metadata": {},
   "source": [
    "There is no dupliacate value too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f04f4",
   "metadata": {},
   "source": [
    "Filter the dataset again to make sure if the data have any Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a2c9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.filter(train.OriginalTweet.isNotNull() & train.Sentiment.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e02621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "UserName          0\n",
       "ScreenName        0\n",
       "Location       8590\n",
       "TweetAt           0\n",
       "OriginalTweet     0\n",
       "Sentiment         0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select([count(when(col(c).isNull(), c)).alias(c) for c in train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c766d",
   "metadata": {},
   "source": [
    "Same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c78bd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of duplicate row: 0\n"
     ]
    }
   ],
   "source": [
    "#Duplicate value\n",
    "print('Total of duplicate row:', train.count() - train.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a41c36af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment         \n",
       "Positive              11422\n",
       "Negative               9917\n",
       "Neutral                7713\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('Sentiment').toPandas().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e4b0a",
   "metadata": {},
   "source": [
    "There is a huge amount of positive and negative Tweet in train dataset with 11k and 10k. Neutral sentiment only 7.7k Tweet so it will be a imbalanced value in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56d346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row after delete invalid value from Sentiment: 41157 rows\n"
     ]
    }
   ],
   "source": [
    "print('Total row after delete invalid value from Sentiment:', train.count(), 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18de538",
   "metadata": {},
   "source": [
    "- In this case, I will combine Extremely Positive into Positive, and Extremely Negative into Negative Sentiments.\n",
    "- Because it's hard to define if the Tweets on the same measurement, It will cause a confict when use tf-idf method.\n",
    "- So that the Sentiment will be 3 now: Positive, Negative and Neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b417ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('Sentiment', when(train.Sentiment == 'Extremely Positive', 'Positive')\\\n",
    "                       .when(train.Sentiment == 'Positive', 'Positive')\n",
    "                      .when(train.Sentiment == 'Extremely Negative', 'Negative')\\\n",
    "                      .when(train.Sentiment == 'Negative', 'Negative')\\\n",
    "                      .otherwise('Neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f45a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive     18046\n",
       "Negative     15398\n",
       "Neutral       7713\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('Sentiment').toPandas().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116742d",
   "metadata": {},
   "source": [
    "- Now the output look better, but there is a small imbalance between group of output in Sentiment value. \n",
    "- The positive is the highest Tweet with 18k and the Negative is 15k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a50c0",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa94ac",
   "metadata": {},
   "source": [
    "Same method with Train dataset, I will check the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a37c6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "UserName       0\n",
       "ScreenName     0\n",
       "Location       0\n",
       "TweetAt        0\n",
       "OriginalTweet  0\n",
       "Sentiment      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nan checking\n",
    "test.select([count(when(isnan(c), c)).alias(c) for c in test.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305cfd3",
   "metadata": {},
   "source": [
    "There is no nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1378fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "UserName         0\n",
       "ScreenName       0\n",
       "Location       834\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null checking\n",
    "test.select([count(when(col(c).isNull(), c)).alias(c) for c in test.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a4ae0",
   "metadata": {},
   "source": [
    "No Null value on OriginalTweet feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34aa20e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of duplicate row: 0\n"
     ]
    }
   ],
   "source": [
    "#Duplicate value\n",
    "print('Total of duplicate row:', test.count() - test.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06ecdc",
   "metadata": {},
   "source": [
    "There is no duplicate row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329d17c",
   "metadata": {},
   "source": [
    "Filter the dataset again to make sure it not Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f449551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the dataset - delete Null row.\n",
    "test = test.filter(test.OriginalTweet.isNotNull() & test.Sentiment.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e4c7ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenName</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweetAt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginalTweet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "UserName         0\n",
       "ScreenName       0\n",
       "Location       834\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select([count(when(col(c).isNull(), c)).alias(c) for c in test.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845d1aa",
   "metadata": {},
   "source": [
    "No more Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25356db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of duplicate row: 0\n"
     ]
    }
   ],
   "source": [
    "#Duplicate value\n",
    "print('Total of duplicate row:', test.count() - test.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48133d92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment         \n",
       "Negative              1041\n",
       "Positive               947\n",
       "Neutral                619\n",
       "Extremely Positive     599\n",
       "Extremely Negative     592\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('Sentiment').toPandas().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c8e61",
   "metadata": {},
   "source": [
    "Also there is a imbalance data between sentiments but not much, it's acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b9228a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row after delete invalid value from Sentiment: 3798 rows\n"
     ]
    }
   ],
   "source": [
    "print('Total row after delete invalid value from Sentiment:', test.count(), 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17ff3d",
   "metadata": {},
   "source": [
    "Transform the Extremely Positive/Negative into Positive/Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166fb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.withColumn('Sentiment', when(test.Sentiment == 'Extremely Positive', 'Positive')\\\n",
    "                       .when(test.Sentiment == 'Positive', 'Positive')\n",
    "                      .when(test.Sentiment == 'Extremely Negative', 'Negative')\\\n",
    "                      .when(test.Sentiment == 'Negative', 'Negative')\\\n",
    "                      .otherwise('Neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60264338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Negative     1633\n",
       "Positive     1546\n",
       "Neutral       619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('Sentiment').toPandas().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb2fe5",
   "metadata": {},
   "source": [
    "Now the test dataset look better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9367b9",
   "metadata": {},
   "source": [
    "### Clean the text value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c8143",
   "metadata": {},
   "source": [
    "Because the OriginalTweet is a combination of link, text, symbol ,etc. So clean the Tweet is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6843e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#delete link\n",
    "train = train.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet')), 'https?://\\S+|www\\.\\S+', \"\"))\n",
    "#delete symbol\n",
    "train = train.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '[^a-zA-z]', \" \"))\n",
    "#delete digits\n",
    "train = train.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '\\d+', \"\"))\n",
    "#delete white space\n",
    "train = train.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '\\s+', \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b1dcd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|OriginalTweet_re                                                                                                                                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| menyrbie phil_gahan chrisitv and and                                                                                                                                                                                                        |\n",
      "|advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order|\n",
      "|coronavirus australia woolworths to give elderly disabled dedicated shopping hours amid covid outbreak                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('OriginalTweet_re').show(3,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2224e8",
   "metadata": {},
   "source": [
    "The Tweet look better than the original Tweet now. And now, I will try with the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a945428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete link\n",
    "test = test.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet')), 'https?://\\S+|www\\.\\S+', \" \"))\n",
    "#delete symbol\n",
    "test = test.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '[^\\w]', \" \"))\n",
    "#delete digits\n",
    "test = test.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '\\d+', \" \"))\n",
    "#delete white space\n",
    "test = test.withColumn('OriginalTweet_re', regexp_replace(lower(col('OriginalTweet_re')), '\\s+', \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bb796ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|OriginalTweet_re                                                                                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|trending new yorkers encounter empty supermarket shelves pictured wegmans in brooklyn sold out online grocers foodkick maxdelivery as coronavirus fearing shoppers stock up |\n",
      "|when i couldn t find hand sanitizer at fred meyer i turned to amazon but for a pack of purell check out how coronavirus concerns are driving up prices                      |\n",
      "|find out how you can protect yourself and loved ones from coronavirus                                                                                                       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.select('OriginalTweet_re').show(3,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0f54b",
   "metadata": {},
   "source": [
    "It's better now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872a46d",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a53860",
   "metadata": {},
   "source": [
    "- The Output have to be indexed to put in predicting model so I will use StringIndexer.\n",
    "- The key feature to decide if the Tweet belonged to which Sentiment is Tweets's content. So I will take OriginalTweet as an input only.\n",
    "- Also I have to transform it by using tf-idf method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8334b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Sentiment value (word) to index\n",
    "indexer_output = StringIndexer(inputCol = 'Sentiment', outputCol = 'Sentiment_idx')\n",
    "#tokenizer for OriginalTweet\n",
    "tokenizer = Tokenizer(inputCol = 'OriginalTweet_re', outputCol = 'OriginalTweet_token')\n",
    "# OriginalTweet token -> stopword\n",
    "stopword = StopWordsRemover(inputCol = 'OriginalTweet_token', outputCol = 'OriginalTweet_stopword')\n",
    "#OriginalTweet stopword -> Count vectorizer (tf)\n",
    "count_vec = CountVectorizer(inputCol = 'OriginalTweet_stopword', outputCol = 'OriginalTweet_countvec', maxDF = 0.7)\n",
    "#OriginalTweet tf -> idf (find the important word)\n",
    "idf = IDF(inputCol = 'OriginalTweet_countvec', outputCol = 'OriginalTweet_idf', minDocFreq = 12)\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['OriginalTweet_idf'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb75268",
   "metadata": {},
   "source": [
    "I will use maxDF to delete some popular word appear in most of the text that thw StopWordRemover function can not detect such as and, in, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20511d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [indexer_output, tokenizer, stopword, count_vec, idf, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40be32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pipeline.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a32d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|Sentiment|Sentiment_idx|\n",
      "+---------+-------------+\n",
      "| Positive|          0.0|\n",
      "| Negative|          1.0|\n",
      "|  Neutral|          2.0|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.select(['Sentiment', 'Sentiment_idx']).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c05043",
   "metadata": {},
   "source": [
    "- The Sentiment will convert to index defined as:\n",
    "    - Positive - 0.0\n",
    "    - Negative - 1.0\n",
    "    - Neutral - 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa4d60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.select(['Sentiment_idx', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dea6d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Sentiment_idx|            features|\n",
      "+-------------+--------------------+\n",
      "|          2.0|(52581,[2],[1.582...|\n",
      "|          0.0|(52581,[11,12,104...|\n",
      "|          0.0|(52581,[0,1,11,60...|\n",
      "+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "462f32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pipeline.fit(test).transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05b83e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.select(['Sentiment_idx', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6eb81975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Sentiment_idx|            features|\n",
      "+-------------+--------------------+\n",
      "|          0.0|(11361,[1,7,11,13...|\n",
      "|          1.0|(11361,[1,14,48,9...|\n",
      "|          1.0|(11361,[1,173,342...|\n",
      "+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96061b8",
   "metadata": {},
   "source": [
    "## Modeling and Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7938b88",
   "metadata": {},
   "source": [
    "### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d4cae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontree_model(train_set, test_set, label):\n",
    "    #build three models\n",
    "    tree = DecisionTreeClassifier(labelCol = label, featuresCol = 'features')\n",
    "    \n",
    "    #Fit 3 model with train dataset\n",
    "    tree_model = tree.fit(train_set)\n",
    "    \n",
    "    #Predict with test dataset\n",
    "    tree_pred = tree_model.transform(test_set)\n",
    "    #tree_prednlabel = tree_pred.select(['prediction', label]).withColumn(label, col(label).cast('float')).orderBy('prediction')\n",
    "\n",
    "    #Select predoction result for evaluate the performance\n",
    "    #accuracy_evaluation = MulticlassClassificationEvaluator(labelCol = 'PrivateIndex', predictionCol = 'prediction',metricName = 'accuracy')\n",
    "    bi_evaluator = BinaryClassificationEvaluator(labelCol = label, rawPredictionCol = 'prediction')\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol = label, predictionCol = 'prediction')\n",
    "    #Evaluate\n",
    "    tree_acc = multi_evaluator.evaluate(tree_pred, {multi_evaluator.metricName: \"accuracy\"})\n",
    "    \n",
    "    tree_auc = bi_evaluator.evaluate(tree_pred, {bi_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "    #save model\n",
    "    #tree_model.save('treemodel_rating')\n",
    "    \n",
    "    #Show the result\n",
    "    print('Accuracy Score:')\n",
    "    print('-'*80)\n",
    "    print('Decision Tree accuracy: {0:2.2f}%'.format(tree_acc*100))\n",
    "\n",
    "    print('\\n')\n",
    "    print('AUC Score:')\n",
    "    print('-'*80)\n",
    "    print('Decision Tree AUC: {0:2.2f}%'.format(tree_auc*100))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Confusion matrix')\n",
    "    print('-'*80)\n",
    "    print('Decision tree')\n",
    "    tree_pred.groupby(label, 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1c331bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Decision Tree accuracy: 44.94%\n",
      "\n",
      "\n",
      "AUC Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Decision Tree AUC: 51.30%\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "--------------------------------------------------------------------------------\n",
      "Decision tree\n",
      "+-------------+----------+-----+\n",
      "|Sentiment_idx|prediction|count|\n",
      "+-------------+----------+-----+\n",
      "|          2.0|       0.0|  579|\n",
      "|          1.0|       1.0|  251|\n",
      "|          0.0|       1.0|  177|\n",
      "|          1.0|       0.0| 1295|\n",
      "|          2.0|       1.0|   40|\n",
      "|          0.0|       0.0| 1456|\n",
      "+-------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decisiontree_model(data_train, data_test, 'Sentiment_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b047c6f",
   "metadata": {},
   "source": [
    "- The model showed that the accuracy in this case is not good.\n",
    "    - Right predict result are 1.7k.\n",
    "    - While wrong result are 2k.\n",
    "    - In this model, It seem like negative Tweet easily misunderstood as positive sentiment.\n",
    "- The accuracy is below 50% which is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33888e19",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2655bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_model(train_set, test_set, label):\n",
    "    #split dataset into train and test set\n",
    "    #train_set, test_set = dataset.randomSplit([0.8, 0.2])\n",
    "    #build three models\n",
    "    forest = RandomForestClassifier(labelCol = label, featuresCol = 'features')\n",
    "    \n",
    "    #Fit 3 model with train dataset\n",
    "    forest_model = forest.fit(train_set)\n",
    "    \n",
    "    #Predict with test dataset\n",
    "    forest_pred = forest_model.transform(test_set)\n",
    "    #tree_prednlabel = tree_pred.select(['prediction', label]).withColumn(label, col(label).cast('float')).orderBy('prediction')\n",
    "\n",
    "    #Select predoction result for evaluate the performance\n",
    "    #accuracy_evaluation = MulticlassClassificationEvaluator(labelCol = 'PrivateIndex', predictionCol = 'prediction',metricName = 'accuracy')\n",
    "    bi_evaluator = BinaryClassificationEvaluator(labelCol = label, rawPredictionCol = 'prediction')\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol = label, predictionCol = 'prediction')\n",
    "    #Evaluate\n",
    "    forest_acc = multi_evaluator.evaluate(forest_pred, {multi_evaluator.metricName: \"accuracy\"})\n",
    "    \n",
    "    forest_auc = bi_evaluator.evaluate(forest_pred, {bi_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "    #save model\n",
    "    #tree_model.save('treemodel_rating')\n",
    "    \n",
    "    #Show the result\n",
    "    print('Accuracy Score:')\n",
    "    print('-'*80)\n",
    "    print('Random Forest accuracy: {0:2.2f}%'.format(forest_acc*100))\n",
    "\n",
    "    print('\\n')\n",
    "    print('AUC Score:')\n",
    "    print('-'*80)\n",
    "    print('Random Forest AUC: {0:2.2f}%'.format(forest_auc*100))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Confusion matrix')\n",
    "    print('-'*80)\n",
    "    print('Random Forest')\n",
    "    forest_pred.groupby(label, 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "602634d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest accuracy: 42.63%\n",
      "\n",
      "\n",
      "AUC Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest AUC: 49.46%\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest\n",
      "+-------------+----------+-----+\n",
      "|Sentiment_idx|prediction|count|\n",
      "+-------------+----------+-----+\n",
      "|          2.0|       0.0|  617|\n",
      "|          1.0|       1.0|   21|\n",
      "|          0.0|       1.0|   35|\n",
      "|          1.0|       0.0| 1525|\n",
      "|          2.0|       1.0|    2|\n",
      "|          0.0|       0.0| 1598|\n",
      "+-------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_model(data_train, data_test, 'Sentiment_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9aed2e",
   "metadata": {},
   "source": [
    "- Also with forest model, the result is not good when there is still alot of wrong prediction negative -> positive.\n",
    "- The accuracy still below 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc7c04",
   "metadata": {},
   "source": [
    "Now I will try with the data just hyave 2 sentiment positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c899e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train1 = data_train.select(['Sentiment_idx', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fe929de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train1 = data_train1.filter(col('Sentiment_idx') != 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82b2987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33444"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d948a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1 = data_test.select(['Sentiment_idx', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "19223f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1 = data_test1.filter(col('Sentiment_idx') != 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f3c37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Decision Tree accuracy: 53.63%\n",
      "\n",
      "\n",
      "AUC Score:\n",
      "--------------------------------------------------------------------------------\n",
      "Decision Tree AUC: 52.64%\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "--------------------------------------------------------------------------------\n",
      "Decision tree\n",
      "+-------------+----------+-----+\n",
      "|Sentiment_idx|prediction|count|\n",
      "+-------------+----------+-----+\n",
      "|          1.0|       1.0|  252|\n",
      "|          0.0|       1.0|  180|\n",
      "|          1.0|       0.0| 1294|\n",
      "|          0.0|       0.0| 1453|\n",
      "+-------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decisiontree_model(data_train1, data_test1, 'Sentiment_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daade5d",
   "metadata": {},
   "source": [
    "The result still showed that Negative tweet (1.0) will be easily predicted to Positive (0.0). It make the model hard to predict correctly due to a variety of human language,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08c3c8",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- In this case, tf-idf approach will not a good method for predicting the Sentiment. Because the language is more variety so that the old method like if-idf will not suitable in some case.\n",
    "- The evidence is user still talk good (positve) about a problem, then they will give some negative idea. The problem is we must know how much (percentage) will positive and negative sentences accounted for in a single Tweets.\n",
    "- You can see that most of Neutral sentiment (2.0) is predicted as Positive sentiment(0.0), that's mean people talk good about something, also with Negative sentiment (1.0) is predicted as Positive (0.0) and this case account the most in the result.\n",
    "- Both tree model give a performance below 50%, but that's not mean the model does not good. It need a difference approach such as use another new transform text data method like sparkNPL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
